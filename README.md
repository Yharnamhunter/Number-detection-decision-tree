# Распознавание рукописных цифр (Decision Tree vs Random Forest)

Проект по классификации рукописных цифр по пиксельным признакам.
Сравниваются две модели: `DecisionTreeClassifier` и `RandomForestClassifier`.
Предобработка: удаление неинформативных пикселей с помощью `VarianceThreshold`.
Качество на тесте оценивается с доверительными интервалами бутстрапом (percentile CI) без дообучения на бутстрап-подвыборках.

## Датасет

Используется набор черно-белых чисел 28x28 пикселей в виде строк с описанием каждого пикселя.

## Методика

* Разбиение на выборки: стратифицированный `train_test_split`.
* `VarianceThreshold` → модель (дерево/лес). Селектор обучается **только** на тренировочной части, чтобы избежать утечки.
* Метрики: `accuracy` и `macro F1` на валидации/тесте.
* Доверительные интервалы на тесте: бутстрап по парам `(y_true, y_pred)` с ресемплированием индексов, 95% percentile CI. Для мультикласса F1 считается с `average="macro"`.

## Репликация результатов

### 1) Установка

```bash
python -m venv .venv
source .venv/bin/activate        # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 2) Запуск ноутбука

Откройте `Number_detection.ipynb` и выполните все ячейки сверху вниз.

### 3) Получение итоговых метрик

В конце ноутбука печатаются метрики на тесте для обеих моделей и их 95% доверительные интервалы.

## Что внутри 

* `VarianceThreshold(threshold=...)` удаляет константные или почти константные пиксели.
* `DecisionTreeClassifier` показывает высокую вариативность и склонность к переобучению.
* `RandomForestClassifier` устойчивее и, как правило, даёт более высокие результаты на тесте.
* Бутстрап-ДИ оценивают неопределённость метрик на тесте без переобучения моделей.

## Результаты

Итоговые числа зависят от случайного разбиения и параметров порога дисперсии.
В ноутбуке зафиксирован `RANDOM_STATE` для воспроизводимости.
